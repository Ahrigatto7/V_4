import streamlit as st
import pandas as pd
import sqlite3
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
import openai

st.title("â‘¡ êµ°ì§‘ë¶„ì„ + ì±—ë´‡ + ìš”ì•½ + ìë™ íƒœê¹… + DB ì €ì¥/ê²€ìƒ‰")

openai_api_key = st.secrets.get("openai_key", "")  # ì‹¤ì œ ì„œë¹„ìŠ¤ì‹œ Secretsì— ì…ë ¥ í•„ìš”

def load_file_to_df(file):
    ext = file.name.split('.')[-1].lower()
    if ext in ["txt", "md"]:
        text = file.read().decode("utf-8")
        df = pd.DataFrame([{"ë³¸ë¬¸": t} for t in text.split('\n') if t.strip()])
    elif ext == "csv":
        df = pd.read_csv(file)
    elif ext in ["xlsx", "xls"]:
        df = pd.read_excel(file)
    else:
        df = pd.DataFrame()
    return df

def simple_rule_match(text: str, rule_patterns: dict):
    return [rule_patterns[k] for k in rule_patterns if k in text]

def run_clustering(cases, n_clusters=5):
    vectorizer = TfidfVectorizer(max_features=60)
    X = vectorizer.fit_transform(cases["case_text"])
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    cases["êµ°ì§‘"] = kmeans.fit_predict(X)
    return cases

def ai_summary(text):
    if not openai_api_key:
        return "(OpenAI APIí‚¤ ì—†ìŒ: ìƒ˜í”Œ ìš”ì•½)\n" + (text[:80] + "..." if len(text) > 80 else text)
    try:
        openai.api_key = openai_api_key
        completion = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": f"ì•„ë˜ ëª…ë¦¬ í…ìŠ¤íŠ¸ë¥¼ 2ì¤„ë¡œ ìš”ì•½:\n{text}"}]
        )
        return completion.choices[0].message['content'].strip()
    except Exception as e:
        return f"(AI ìš”ì•½ ì˜¤ë¥˜) {e}"

def auto_tags(text, tag_patterns=None):
    if tag_patterns is None:
        tag_patterns = [
            "ê³µë§", "ê·€ê²©", "ìƒê´€ê²©", "ì…ë¬˜", "ê´€ì„±", "ì‹ì‹ ", "ì¬ì‚´", "ì í¬", "ì™•ì§€", "ì¸ì„±", "ë¹„ê²",
            "í•©", "ì¶©", "íŒŒ", "í˜•", "ë¬˜", "ê´€ì¬", "ì‚¬ì—…", "ì´í˜¼", "ì·¨ì—…", "í•©ê²©"
        ]
    tags = [tag for tag in tag_patterns if tag in text]
    return tags

# --- íŒŒì¼ ì—…ë¡œë“œ
file = st.file_uploader("íŒŒì¼ ì—…ë¡œë“œ", type=["txt", "md", "csv", "xlsx", "xls"])
if file:
    df = load_file_to_df(file)
    st.dataframe(df)
    st.session_state["df"] = df

if st.session_state.get("df", None) is not None:
    df = st.session_state["df"]
    texts = df.iloc[:,0].dropna().astype(str).tolist()
    cases = [t.strip() for t in texts if len(t.strip()) > 10]
    cases_df = pd.DataFrame({'case_text': cases})

    # ê·œì¹™ íƒœê¹…
    rule_patterns = {
        "í—ˆíˆ¬": "í—ˆíˆ¬ëŠ” ì„±ë³„/ìœ ë¬´ ë³€ë™",
        "ì…ë¬˜": "ì…ë¬˜ì‹œ ì„±ë³„ë³€í™”/ë¬´ìì‹ ê°€ëŠ¥",
        "ê³µë§": "ê³µë§ì€ ìì‹ìš´ ì•½í™”",
        "ê´€ì„±": "ê´€ì„±ì€ ìì‹ì„±(ë‚¨ëª…)",
        "ì‹ì‹ ": "ì—¬ëª…ì€ ì‹ì‹ /ìƒê´€ì´ ìì‹"
    }
    cases_df['matched_rules'] = cases_df['case_text'].apply(lambda x: simple_rule_match(x, rule_patterns))
    cases_df['joined_rules'] = cases_df['matched_rules'].apply(lambda x: "; ".join(x) if x else "")

    # AI ìš”ì•½ ë° ìë™ íƒœê¹…
    with st.spinner("AI ìš”ì•½/íƒœê¹… ì¤‘..."):
        cases_df['ìš”ì•½'] = cases_df['case_text'].apply(ai_summary)
        cases_df['ìë™íƒœê·¸'] = cases_df['case_text'].apply(auto_tags)

    n_clusters = st.slider("êµ°ì§‘ ê°œìˆ˜", 2, min(10, len(cases_df)), 5)
    cases_df = run_clustering(cases_df, n_clusters)
    st.dataframe(cases_df)

    # ì±—ë´‡(ì‹¬í”Œ) - í…ìŠ¤íŠ¸ ê²€ìƒ‰ ê¸°ë°˜
    st.markdown("### ğŸ’¬ ì‚¬ë¡€ ì±—ë´‡/ê²€ìƒ‰")
    chat_q = st.text_input("ê¶ê¸ˆí•œ ì , í‚¤ì›Œë“œ, ì§ˆë¬¸ì„ ì…ë ¥")
    if chat_q:
        found = cases_df[cases_df['case_text'].str.contains(chat_q)]
        if not found.empty:
            st.write("ê´€ë ¨ ì‚¬ë¡€(ìƒìœ„ 3ê°œ):")
            for i, row in found.head(3).iterrows():
                st.info(f"ì‚¬ë¡€ {i+1}\n\n{row['ìš”ì•½']}")
        else:
            st.warning("í•´ë‹¹ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ëŠ” ì‚¬ë¡€ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # DB ìë™ ì €ì¥
    db_name = "analysis.db"
    table_name = "case_analysis"
    with sqlite3.connect(db_name) as con:
        cases_df.to_sql(table_name, con, if_exists="replace", index=False)
    st.success(f"DBì— ìë™ ì €ì¥ ì™„ë£Œ: {db_name} [{table_name}]")

    st.markdown("### ğŸ” DB ì €ì¥ ë°ì´í„° ì¦‰ì‹œ ê²€ìƒ‰")
    with sqlite3.connect(db_name) as con:
        query = st.text_input("DBì—ì„œ ê²€ìƒ‰ì–´(ë³¸ë¬¸/ìš”ì•½/íƒœê·¸/ë£° ë“±)")
        q = f"SELECT * FROM {table_name}"
        if query:
            q += f" WHERE case_text LIKE '%{query}%' OR joined_rules LIKE '%{query}%' OR ìš”ì•½ LIKE '%{query}%' OR ìë™íƒœê·¸ LIKE '%{query}%'"
        result_df = pd.read_sql(q, con)
        st.dataframe(result_df)
        st.bar_chart(result_df['êµ°ì§‘'].value_counts())

    st.download_button("ë¶„ì„ê²°ê³¼(Excel) ë‹¤ìš´ë¡œë“œ", cases_df.to_csv(index=False), file_name="ë¶„ì„ê²°ê³¼.csv")
else:
    st.info("íŒŒì¼ ì—…ë¡œë“œ í›„ êµ°ì§‘ë¶„ì„ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
